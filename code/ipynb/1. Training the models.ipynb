{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training models and choosing the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will be using nltk libraries to process the natural language, tokenize them and then assign sentimental values and label them using multiple algorithms\n",
    "\n",
    "import random\n",
    "import pickle\n",
    "from nltk.probability import FreqDist\n",
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC, NuSVC\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Pickled!\n",
      "Word_Features Pickled!\n"
     ]
    }
   ],
   "source": [
    "short_pos = open(\"short_reviews/positive.txt\", \"r\").read()\n",
    "short_neg = open(\"short_reviews/negative.txt\", \"r\").read()\n",
    "\n",
    "documents, all_words = [], []\n",
    "\n",
    "#  j is adject,\n",
    "allowed_word_types = [\"J\"]\n",
    "\n",
    "for p in short_pos.split('\\n'):\n",
    "    documents.append((p, \"pos\"))\n",
    "    part_of_speech = pos_tag(word_tokenize(p))\n",
    "    for w in part_of_speech:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "            \n",
    "for n in short_neg.split('\\n'):\n",
    "    documents.append((n, \"neg\"))\n",
    "    part_of_speech = pos_tag(word_tokenize(n))\n",
    "    for w in part_of_speech:\n",
    "        if w[1][0] in allowed_word_types:\n",
    "            all_words.append(w[0].lower())\n",
    "\n",
    "            \n",
    "            \n",
    "save_documents = open(\"pickles/documents.pickle\", \"wb\") \n",
    "pickle.dump(documents, save_documents)\n",
    "save_documents.close()\n",
    "\n",
    "print (\"Documents Pickled!\")\n",
    "            \n",
    "    \n",
    "    \n",
    "all_words = FreqDist(all_words)\n",
    "\n",
    "word_features = list(all_words.keys())[:6000]\n",
    "\n",
    "save_word_features = open(\"pickles/word_features.pickle\", \"wb\")\n",
    "pickle.dump(word_features, save_word_features)\n",
    "save_word_features.close()\n",
    "\n",
    "print (\"Word_Features Pickled!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_features(document):\n",
    "    words = word_tokenize(document)\n",
    "    features = {}\n",
    "    for w in word_features:\n",
    "        features[w] = (w in words)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features selected:  10664\n",
      "Naive Bayes Classifier Accuracy :  72.59036144578313\n",
      "Most Informative Features\n",
      "                    flat = True              neg : pos    =     22.2 : 1.0\n",
      "              engrossing = True              pos : neg    =     20.4 : 1.0\n",
      "                  boring = True              neg : pos    =     19.3 : 1.0\n",
      "                 generic = True              neg : pos    =     16.9 : 1.0\n",
      "                mediocre = True              neg : pos    =     16.2 : 1.0\n",
      "               inventive = True              pos : neg    =     15.1 : 1.0\n",
      "              refreshing = True              pos : neg    =     14.4 : 1.0\n",
      "                 routine = True              neg : pos    =     13.6 : 1.0\n",
      "                    warm = True              pos : neg    =     12.7 : 1.0\n",
      "                powerful = True              pos : neg    =     12.5 : 1.0\n",
      "               wonderful = True              pos : neg    =     12.3 : 1.0\n",
      "                mindless = True              neg : pos    =     11.6 : 1.0\n",
      "               realistic = True              pos : neg    =     10.4 : 1.0\n",
      "             mesmerizing = True              pos : neg    =     10.4 : 1.0\n",
      "                    dull = True              neg : pos    =     10.3 : 1.0\n",
      "Naive Bayes Pickled!\n"
     ]
    }
   ],
   "source": [
    "featuresets = [(find_features(rev), category) for (rev, category) in documents]\n",
    "\n",
    "random.shuffle(featuresets)\n",
    "print (\"Number of features selected: \", len(featuresets))\n",
    "\n",
    "train_data = featuresets[:10000]\n",
    "test_data = featuresets[10000:]\n",
    "\n",
    "NB_classifier = NaiveBayesClassifier.train(train_data)\n",
    "print (\"Naive Bayes Classifier Accuracy : \", (accuracy(NB_classifier, test_data)) * 100)\n",
    "NB_classifier.show_most_informative_features(15)\n",
    "\n",
    "save_classifier = open(\"pickles/Naive_Bayes.pickle\", \"wb\") \n",
    "pickle.dump(NB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "print (\"Naive Bayes Pickled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarly done for all other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNB Classifier Accuracy :  73.64457831325302\n",
      "Multinomial NB Pickled!\n",
      "BernoulliNB Classifier Accuracy :  73.04216867469879\n",
      "Bernoulli NB Pickled!\n",
      "Logistic Regression Pickled!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier Accuracy :  69.87951807228916\n",
      "SGD Classifier Pickled!\n",
      "LinearSVC Classifier Accuracy :  69.7289156626506\n",
      "Linear SVC Pickled!\n",
      "NuSVC Classifier Accuracy :  72.43975903614458\n",
      "NuSVC Pickled!\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(train_data)\n",
    "print (\"MNB Classifier Accuracy : \", (accuracy(MNB_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/Multinomial_NB.pickle\", \"wb\") \n",
    "pickle.dump(MNB_classifier, save_classifier)\n",
    "save_classifier.close()   \n",
    "\n",
    "print (\"Multinomial NB Pickled!\")\n",
    "\n",
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(train_data)\n",
    "print (\"BernoulliNB Classifier Accuracy : \", (accuracy(BernoulliNB_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/Bernoulli_NB.pickle\", \"wb\") \n",
    "pickle.dump(BernoulliNB_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print (\"Bernoulli NB Pickled!\")\n",
    "\n",
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(train_data)\n",
    "#print (\"LogisticRegression Classifier Accuracy : \", (accuracy(LogisticRegression_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/Logistic_Regression.pickle\", \"wb\") \n",
    "pickle.dump(LogisticRegression_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print (\"Logistic Regression Pickled!\")\n",
    "\n",
    "SGD_classifier = SklearnClassifier(SGDClassifier())\n",
    "SGD_classifier.train(train_data)\n",
    "print (\"SGD Classifier Accuracy : \", (accuracy(SGD_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/SGD_Classifier.pickle\", \"wb\") \n",
    "pickle.dump(SGD_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print (\"SGD Classifier Pickled!\")\n",
    "\n",
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(train_data)\n",
    "print (\"LinearSVC Classifier Accuracy : \", (accuracy(LinearSVC_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/Linear_SVC.pickle\", \"wb\") \n",
    "pickle.dump(LinearSVC_classifier, save_classifier)\n",
    "save_classifier.close()   \n",
    "\n",
    "print (\"Linear SVC Pickled!\")\n",
    "\n",
    "NuSVC_classifier = SklearnClassifier(NuSVC())\n",
    "NuSVC_classifier.train(train_data)\n",
    "print (\"NuSVC Classifier Accuracy : \", (accuracy(NuSVC_classifier, test_data)) * 100)\n",
    "\n",
    "save_classifier = open(\"pickles/Nu_SVC.pickle\", \"wb\") \n",
    "pickle.dump(NuSVC_classifier, save_classifier)\n",
    "save_classifier.close()\n",
    "\n",
    "print (\"NuSVC Pickled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## go to next file for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
